---
title: 熵权法
mathjax: True
date: 2021-07-24 10:20:21
summary: 依照样本中指标分布分配权重
categories: Math
tags:
  - weight
---

# 信息量

事件A：小明穿着西装出门参加活动。

事件B：小明穿着女装出门参加活动。

仅凭直觉来说，显而易见事件B的信息量比事件A的信息量要大。究其原因，是因为事件A发生的概率很大，事件B发生的概率很小。所以当越不可能的事件发生了，我们获取到的信息量就越大。越可能发生的事件发生了，我们获取到的信息量就越小。

因此：对于一个事件，其发生概率越小那么其所包含的信息量越大。

进一步的给上述的现象进行建模，表达一类问题，定义信息量如下：
$$
I(x) = - log(p(x))
$$
**Q**：越小越大的现象为什么不用 $I(x) = \frac{1}{p(x)}$ ？

**A**：虽然这个建模能够表达上述的现象，但是我们最常处理的肯定是多个事件之间信息量的关系，针对多个事件，这个正三角表达式（上简下繁）计算就较为复杂，不易化简，因此选择了更易于计算的对数形式。

# 熵

熵是对一个随机变量 $X$（可能有 $n$ 种事件）信息量的期望 $H(X)$，表示对信息不确定性的度量。

信息量越大（该事件的多种情况发生的可能性两级分化就越严重）代表该事件的不确定性越小，因此信息熵越小。
$$
H(X) = - \sum_{i=1}^{n} p(x_i) log (p(x_i))
$$
针对不可能事件，我们定义其不确定性为 0

因此可以确定其取值范围：$[0, logn]$，出现必然事件时达到最小值，所有事件发生概率一致时达到最大值。

例如：伯努利分布下熵与概率的关系展示：

![image-20210722125918351](https://raw.githubusercontent.com/Coming98/pictures/main/image-20210722125918351.png)

# 熵权法

使用熵权法计算各个**指标的权重**：熵权法的旨在根据样本中单一指标信息熵的大小来确定权重

后文中我们使用 $\{1, \dots, i,\dots n\}$ 表示样本，使用 $\{1, \dots, j,\dots n\}$ 表示指标

* 若某个指标的信息熵 $H(j)$ 越小，表明指标值得不确定性越小，因而提供的信息量越多（可能发生非常正常，但是不发生带来的信息量是巨大的），在综合评价中所能起到的作用也越大，其权重也就越大。
* 若某个指标的信息熵 $H(j)$ 越大，表明指标值得不确定性越大，因而提供的信息量越少（无论发不发生感觉都正常），在综合评价中所起到的作用也越小，其权重也就越小。

接下来开始进行权重计算

## Ⅰ 数据标准化

首先将各个指标对应的数据列进行标准化处理，整体数据我们使用 $X$ 表示，$X_{ij}$ 表示第 $i$ 个样本的  第 $j$ 个指标对应的值
$$
X_{ij}=\dfrac{X_{ij} - min(X_j)}{max(x_j) - min(x_j)}
$$

## Ⅱ 计算信息熵

由前文所述，第 $j$ 个指标的信息熵 $H(j)$ 为：
$$
H(j) = - \sum_{i=1}^{n} p(i,j) \cdot log(p(i,j))
$$
其中 $p(i,j) = X_{ij} / \sum_{i=1}^{n}X_{ij}$

为了后续分配权重，我们进一步将信息熵映射到 $[0,1]$ 的范围，由前文所述信息熵 $H(j)$ 的取值范围为$[0, logn]$，因此：
$$
H(j) = - \frac{1}{logn} \sum_{i=1}^{n} p(i,j) \cdot log(p(i,j))
$$

## Ⅲ 确定各指标权重

$$
W_j = \dfrac{1-E_j}{J-\sum_{j=1}^{J} E_j}
$$

由前文所述，信息熵 $H(j)$ 越小，其分配的权重应越大，$E_j \in [0,1]$ 因此 $1 - E_j$ 表明第 $j$ 个指标的权重度量，$J-\sum_{j=1}^{J} E_j$ 表明所有指标的权重度量和，则第 $j$ 个指标的权重值 $W_j$ 即为其权重度量的占比。
