---
title: '【统计学习方法】概论篇'
date: 2021-07-07 21:39:33
summary: '统计学习方法的基础知识【保持更新】'
categories: 统计学习方法
tags: ML
mathjax: true
---

# 概论-学前须知

本文可以充当一个对较小知识点的速查速忆，大部分知识点并不会讲解细致~

统计学习方法学习过程中记录的基础知识，保持更新~

# 综述

## 准备

1. 数据：得到一个有限的训练数据集合；
2. 模型：包含所有可能的模型的假设空间，即学习模型的集合；
3. 损失函数：确定模型选择的准则，即学习的策略；
4. 优化算法：实现求解最优模型的算法，即学习的算法：
5. 最优模型：通过学习方法选择最优模型：
6. 预测：利用学习的最优模型对新数据进行预测或分析。 

## 描述

![image-20210709201408068](https://gitee.com/Butterflier/pictures/raw/master/image-20210709201408068.png)

如上图所示：

1. 从给定的、有限的、用于学习的**训练数据集**（training data）合出发
2. 从**假设空间**（hypothesis space）取出一个模型
3. 将数据输入模型，并应用到某个评价标准上（**损失函数**）
4. 利用选定的优化算法，不断的优化模型
5. 最终得到最终（最优）模型

# 三要素

## 模型

模型就是所要学习的条件概率分布或决策函数

针对概率模型，模型为条件概率分布

针对非概率 模型，模型为决策函数

## 策略

选择最优模型的方法（策略）

**期望风险**：又名风险函数，度量平均意义下模型预测的好坏，是模型关于联合分布的期望损失。
$$
R_{exp}(f) = E_p[L(Y, f(X))] = \int_{x \times y} L(y, f(x)) P(x, y) dxdy
$$
但是问题中实际分布 $P(x,y)$ 通常是未知的，实际中常使用经验风险来代替期望风险

**经验风险**：给定模型关于训练数据集的平均损失，当样本容量N趋于无穷时，经验风险趋近于期望风险（大数定律）
$$
R_{emp}(f) = \frac{1}{N} \sum_{i=1}^{N} L(y_i, f(x_i))
$$
策略便可以推出：经验风险最小化 - $\mathop{min}\limits_{f \in \mathcal{F}} \frac{1}{N} \sum_{i=1}^{N} L(y_i, f(x_i))$

但是会存在过拟合的现象，因此加入对决策函数的约束，引入结构风险最小化：
$$
\mathop{min}\limits_{f \in \mathcal{F}} \frac{1}{N} \sum_{i=1}^{N} L(y_i, f(x_i)) + \lambda J(f)
$$

期望风险与经验风险的联系：由于实际分布P(x,y)不知道实际中常用经验风险代替期望风险

![image-20210707215504624](https://gitee.com/Butterflier/pictures/raw/master/image-20210707215504624.png)

## 算法

学习模型的具体计算方法：梯度下降…

# 概率

## Theory

**独立**：两不同随机变量的取值互不影响：第一次抛硬币和第二次抛硬币得到的结果是相互独立的。

**独立同分布**：指一组随机变量中每个变量的概率分布都相同，且这些随机变量互相独立

**过拟合现象**：一味追求提高对训练数据的预测能力，所选模型的复杂度则往往会比真模型更高。对已知数据预测很好，对未知数据预测很差

**正则化项**：选择经验风险和模型复杂度同时较小的模型

**先验概率**：指根据以往经验和分析得到的概率，如全概率公式

**后验概率**：指在得到“结果”的信息后重新修正的概率，是“执果寻因”问题中的"果"

> 目标事件还没有发生，求这件事情发生的可能性的大小，是先验概率。
>
> 目标事件已发生，求事情发生的原因是由某因素引起的可能性大小，是后验概率。
>
> Example：目标事件是用苹果电脑的人是不是程序员 - $P(dev|apple)$
>
> 现实中我们可以知道使用苹果的人数占比即：$P(apple)$，以及使用苹果电脑的人是程序员的概率：$P(dev|apple)$ - 先验
>
> 而需求是已知一个人是程序员，问他使用苹果电脑的概率 $P(apple|dev)$ - 后验
> $$
> P(apple|dev) = \frac{P(dev|apple)P(apple)}{P(dev|apple)P(apple)+P(dev|!apple)P(!apple)}
> $$



## Equation

**贝叶斯公式**：$P(X|Y) = \frac{P(Y|X) \times P(X) }{P(Y)}$

**全概率公式**：$P(Y) = P(Y|X_1)P(X_1) + P(Y|X_2)P(X_2) + \dots + P(Y |X_n)P(X_n)$

**结合**：$P(X_i|Y) = \frac{P(Y|X_i)P(X_i) }{P(Y|X_1)P(X_1) + P(Y|X_2)P(X_2) + \dots + P(Y |X_n)P(X_n)}$

**切比雪夫大数定理**：随着样本容量n的增加，样本平均数接近于总体平均数，从而根据样本平均数估计总体平均数。

# 数学

## 范数

* L1 范数：向量元素绝对值之和

$$
||x||_1 = \sum_{i=1}^{n}|x_i|
$$

* L2 范数：欧几里得范数，常用于计算向量长度，向量元素绝对值的平方再开方

$$
||x||_2 = \left(\sum_{i=1}^{n}|x_i|^2 \right)^{\frac{1}{2}}
$$

* $+\infty$ 范数：所有向量元素绝对值中最大值

$$
||x||_{+\infin} = \mathop{max}\limits_{i}|x_i|
$$

* $-\infty$ 范数：所有向量元素绝对值中最小值

$$
||x||_{-\infin} = \mathop{min}\limits_{i}|x_i|
$$

* $L_p$ 范数：即统一形式，向量元素绝对值的p次方和的1/p次幂

$$
||x||_p = \left(\sum_{i=1}^{n}|x_i|^p \right)^{\frac{1}{p}}
$$

