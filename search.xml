<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>[统计学习方法]概论篇</title>
      <link href="/Coming-blog/2021/07/07/91-tong-ji-xue-xi-fang-fa-93-gai-lun-pian/"/>
      <url>/Coming-blog/2021/07/07/91-tong-ji-xue-xi-fang-fa-93-gai-lun-pian/</url>
      
        <content type="html"><![CDATA[<h1 id="概论-学前须知"><a href="#概论-学前须知" class="headerlink" title="概论-学前须知"></a>概论-学前须知</h1><p>统计学习方法学习过程中记录的基础知识，保持更新~</p><h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><ol><li>数据：得到一个有限的训练数据集合；</li><li>模型：包含所有可能的模型的假设空间，即学习模型的集合；</li><li>损失函数：确定模型选择的准则，即学习的策略；</li><li>优化算法：实现求解最优模型的算法，即学习的算法：</li><li>最优模型：通过学习方法选择最优模型：</li><li>预测：利用学习的最优模型对新数据进行预测或分析。 </li></ol><h2 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h2><p><img src="https://gitee.com/Butterflier/pictures/raw/master/image-20210707214412171.png" alt="image-20210707214412171"></p><p>如上图所示：</p><ol><li>从给定的、有限的、用于学习的<strong>训练数据集</strong>（training data）合出发</li><li>从<strong>假设空间</strong>（hypothesis space）取出一个模型</li><li>将数据输入模型，并应用到某个评价标准上（<strong>损失函数</strong>）</li><li>利用选定的优化算法，不断的优化模型</li><li>最终得到最终（最优）模型</li></ol><h1 id="三要素"><a href="#三要素" class="headerlink" title="三要素"></a>三要素</h1><p><strong>期望风险</strong></p><p>又名风险函数，度量平均意义下模型预测的好坏，是模型关于联合分布的期望损失。<br>$$<br>R_{exp}(f) = E_p[L(Y, f(X))] = \int_{x \times y} L(y, f(x)) P(x, y) dxdy<br>$$<br><strong>经验风险</strong></p><p>给定模型关于训练数据集的平均损失，当样本容量N趋于无穷时，经验风险趋近于期望风险（大数定律）<br>$$<br>R_{emp}(f) = \frac{1}{N} \sum_{i=1}^{N} L(y_i, f(x_i))<br>$$<br>期望风险与经验风险的联系：由于实际分布P(x,y)不知道实际中常用经验风险代替期望风险</p><p><img src="https://gitee.com/Butterflier/pictures/raw/master/image-20210707215504624.png" alt="image-20210707215504624"></p><h1 id="数学"><a href="#数学" class="headerlink" title="数学"></a>数学</h1><h2 id="范数"><a href="#范数" class="headerlink" title="范数"></a>范数</h2><ul><li>L1范数：向量元素绝对值之和</li></ul><p>$$<br>||x_1|| = \sum_{i=1}^{n}|x_i|<br>$$</p><ul><li></li></ul>]]></content>
      
      
      <categories>
          
          <category> 统计学习方法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分词器Tokenizer使用方法与实践</title>
      <link href="/Coming-blog/2021/07/07/fen-ci-qi-tokenizer-shi-yong-fang-fa-yu-shi-jian/"/>
      <url>/Coming-blog/2021/07/07/fen-ci-qi-tokenizer-shi-yong-fang-fa-yu-shi-jian/</url>
      
        <content type="html"><![CDATA[<h1 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h1><p>该类允许使用两种方法向量化一个文本语料库：</p><ol><li>将每个文本转化为一个整数序列（每个整数都是词典中标记的索引）</li><li>将每个文本转化为一个向量，其中每个标记的系数可以是二进制值、词频、TF-IDF权重等。</li></ol><p>Tips：词索引分配从 1 开始</p><p>Tips：基于词频保留 <code>num_words - 1</code> 个词，其余词将会像过滤字符过滤掉</p><pre class=" language-python"><code class="language-python">keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>text<span class="token punctuation">.</span>Tokenizer<span class="token punctuation">(</span>    num_words<span class="token operator">=</span>None<span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 处理最大单词数目(num_words-1)，基于词频筛选</span>    filters<span class="token operator">=</span><span class="token string">"!"</span><span class="token comment" spellcheck="true">#$%&amp;()*+,-./:;&lt;=>?@[\]^_`&amp;#123;|&amp;#125;~ ", # 过滤的元素，字符级匹配过滤</span>    lower<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 是否将文本转为小写</span>    split<span class="token operator">=</span><span class="token string">" "</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 词分隔符</span>    char_level<span class="token operator">=</span><span class="token boolean">False</span> <span class="token comment" spellcheck="true"># 如果为 True，则每个字符都将被视为标记。</span><span class="token punctuation">)</span></code></pre><h1 id="Attributes"><a href="#Attributes" class="headerlink" title="Attributes"></a>Attributes</h1><p>数据格式如：语料库 - <code>texts</code> = <code>[ document1:&quot;AAAA.BBBB.CCCC.&quot;, document2, ...]</code></p><pre class=" language-python"><code class="language-python">document_countword_counts <span class="token comment" spellcheck="true"># 词在语料库中的频数</span>word_docs <span class="token comment" spellcheck="true"># 词在 documents 中出现的频数，用于 TF-IDF 算法</span><span class="token triple-quoted-string string">"""for w in seq:    if w in self.word_counts:        self.word_counts[w] += 1    else:        self.word_counts[w] = 1for w in set(seq):    # In how many documents each word occurs    self.word_docs[w] += 1"""</span>index_docs <span class="token comment" spellcheck="true"># 同 word_docs 只不过将词映射为了索引值</span>index_word <span class="token comment" spellcheck="true"># 索引 To 词的映射词典</span>word_index <span class="token comment" spellcheck="true"># 词 To 索引的映射词典</span></code></pre><h1 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h1><p>总体来说就是完成了语料库中 Token 与 index 的映射支持，映射以词频为基础</p><pre class=" language-python"><code class="language-python">fit_on_sequences<span class="token punctuation">(</span>sequences<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 列表，内部元素为单词索引</span>fit_on_texts<span class="token punctuation">(</span>texts<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 列表，内部元素为分词后的单个 token</span>sequences_to_matrix<span class="token punctuation">(</span>sequences<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'binary'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 将各个语料的元素索引信息转为 numpy 矩阵 - 通常用于构建数据集</span>sequences_to_texts<span class="token punctuation">(</span>sequences<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># list of word indices(int) TO list of tokens(string)</span>texts_to_sequences<span class="token punctuation">(</span>texts<span class="token punctuation">)</span>get_config<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 字典，返回 tokenizer 实例的配置信息</span>to_json <span class="token comment" spellcheck="true"># json，返回 tokenizer 实例的配置信息</span></code></pre><ol><li>通过 <code>fit_on_texts</code> 完成 Tokenizer 的拟合，更新 Attributes <code>document_count, word_counts, word_docs, index_docs, index_word, word_index</code></li><li>通过内置方法或属性名获取相关信息</li></ol><h1 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h1><p>语料库数据如下：</p><pre class=" language-python"><code class="language-python">texts <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'United were league champions last season.'</span><span class="token punctuation">,</span>        <span class="token string">"They're in a different league from us."</span><span class="token punctuation">,</span>        <span class="token string">"the League of Nations"</span><span class="token punctuation">,</span>        <span class="token string">"a meeting of the Women's League for Peace"</span><span class="token punctuation">,</span>        <span class="token string">"Her success has taken her out of my league"</span><span class="token punctuation">]</span></code></pre><p>测试如下</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">test_default</span><span class="token punctuation">(</span>title<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">:</span>    fit_req <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>fit_on_texts<span class="token punctuation">(</span>texts<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># return None</span>    <span class="token comment" spellcheck="true"># 文本未分词先进行分词，然后将词转为索引值</span>    seq <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>texts_to_sequences<span class="token punctuation">(</span>texts<span class="token punctuation">)</span>    seq_arr <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>sequences_to_matrix<span class="token punctuation">(</span>seq<span class="token punctuation">)</span>    <span class="token triple-quoted-string string">"""    seq : 可以看出 1 的位置是词频最高的 league    [[6, 7, 1, 8, 9, 10],    [11, 12, 3, 13, 1, 14, 15],    [4, 1, 2, 16],    [3, 17, 2, 4, 18, 1, 19, 20],    [5, 21, 22, 23, 5, 24, 2, 25, 1]]    seq_arr: 过长，请看下方示例    """</span><span class="token keyword">def</span> <span class="token function">test_limit_numWords</span><span class="token punctuation">(</span>title<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span><span class="token punctuation">:</span>    tokenizer<span class="token punctuation">.</span>fit_on_texts<span class="token punctuation">(</span>texts<span class="token punctuation">)</span>    seq <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>texts_to_sequences<span class="token punctuation">(</span>texts<span class="token punctuation">)</span>    seq_arr <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>sequences_to_matrix<span class="token punctuation">(</span>seq<span class="token punctuation">)</span>    texts_from_seq <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>sequences_to_texts<span class="token punctuation">(</span>seq<span class="token punctuation">)</span>    <span class="token triple-quoted-string string">"""    seq : 词频低的词直接舍去，知保留词频较高的前 num_words - 1 个词    [[6, 7, 1, 8, 9],     [3, 1],     [4, 1, 2],     [3, 2, 4, 1],     [5, 5, 2, 1]]    seq_arr : 索引 0 保留，因此词典数目为 seq_arr.shape[1]    [[0. 1. 0. 0. 0. 0. 1. 1. 1. 1.]     [0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]     [0. 1. 1. 0. 1. 0. 0. 0. 0. 0.]     [0. 1. 1. 1. 1. 0. 0. 0. 0. 0.]     [0. 1. 1. 0. 0. 1. 0. 0. 0. 0.]]     texts_from_seq :     ['united were league champions last',     'a league',     'the league of',     'a of the league',     'her her of league']    """</span><span class="token triple-quoted-string string">"""Attributes'document_count': 5'word_counts': '&amp;#123;"united": 1, "were": 1, ... "her": 2, "my": 1&amp;#125;''word_docs': '&amp;#123;"united": 1, ... , "her": 1, "my": 1&amp;#125;''index_docs': '&amp;#123;"6": 1, "8": 1, ... "25": 1&amp;#125;''index_word': '&amp;#123;"1": "league", "2": "of", "3": "a", ... "24": "out", "25": "my"&amp;#125;''word_index': '&amp;#123;"league": 1, "of": 2, "a": 3, ... "out": 24, "my": 25&amp;#125;'"""</span><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    tokenizer_default <span class="token operator">=</span> Tokenizer<span class="token punctuation">(</span><span class="token punctuation">)</span>    tokenizer_limit_numWords <span class="token operator">=</span> Tokenizer<span class="token punctuation">(</span>num_words<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 只考虑词频前9的词</span>    test_default<span class="token punctuation">(</span><span class="token string">"default test"</span><span class="token punctuation">,</span> tokenizer_default<span class="token punctuation">)</span>    test_limit_numWords<span class="token punctuation">(</span><span class="token string">"limit num_words test"</span><span class="token punctuation">,</span> tokenizer_limit_numWords<span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    main<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><hr><p>如果存在错误，欢迎留言指出哦~</p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> keras </tag>
            
            <tag> tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>github pages 个人博客搭建部署记录</title>
      <link href="/Coming-blog/2021/04/29/github-pages-ge-ren-bo-ke-da-jian-bu-shu-ji-lu/"/>
      <url>/Coming-blog/2021/04/29/github-pages-ge-ren-bo-ke-da-jian-bu-shu-ji-lu/</url>
      
        <content type="html"><![CDATA[<p>基础版的 Github Pages + Hexo + travis ci 实现个人博客配置</p><p>即使是在众多大佬博客的帮助下，整体配置过程也有些艰辛，让我最头疼的就是网络问题，感觉给 git 配了代理，改了 hosts 也没有什么用</p><p>回来了 - 2021年7月5日23:53:13</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><strong>Tips</strong>：注意主路线教程中使用的是 travis-ci.org, 这个网站马上就要关闭了，其功能迁移到了 <a target="_blank" rel="noopener" href="https://travis-ci.com/">travis-ci.com</a></p><h2 id="主路线"><a href="#主路线" class="headerlink" title="主路线"></a>主路线</h2><p>【Hexo】使用Hexo+github pages+travis ci 实现自动化部署 - <a target="_blank" rel="noopener" href="https://www.cnblogs.com/mfrank/p/12829882.html">HERE</a></p><p>【Hexo】自定义 Hexo 配置文件 - <a target="_blank" rel="noopener" href="https://www.cnblogs.com/mfrank/p/12830094.html">HERE</a></p><p>【Hexo】Hexo 主题 Matery 配置 - <a target="_blank" rel="noopener" href="https://www.cnblogs.com/mfrank/p/12830097.html">HERE</a></p><h2 id="辅助路线"><a href="#辅助路线" class="headerlink" title="辅助路线"></a>辅助路线</h2><p>主路线使用的主题为 <code>matery</code> 其 官方配置地址 (Github Address) - <a target="_blank" rel="noopener" href="https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md">HERE</a></p><p>比较好看的一个最终话风格 - <a target="_blank" rel="noopener" href="https://matjenin.gitee.io/index.html">HERE</a></p><p>在一些配置文件等遇到的特殊字符转义问题  - <a target="_blank" rel="noopener" href="https://wxnacy.com/2018/01/12/hexo-specific-symbol/">HERE</a></p><p>HEXO 官方主题库 - <a target="_blank" rel="noopener" href="https://hexo.io/themes/">HERE</a></p><p>HEXO 官方ICON库 - <a target="_blank" rel="noopener" href="https://fontawesome.com/icons?d=gallery&p=2">HERE</a></p><p>YAML语言简版教程，便于理解和自定义 <code>*.yml</code> <a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blog/2016/07/yaml.html">HERE</a></p><p>LiveRe 留言评论功能配置 - <a target="_blank" rel="noopener" href="https://starslove.me/2020/07/08/Hexo-comment/">HERE</a></p><p>高水平插件 - <a target="_blank" rel="noopener" href="https://blog.csdn.net/q2158798/article/details/82354154">HERE</a></p><h1 id="Hexo-项目目录"><a href="#Hexo-项目目录" class="headerlink" title="Hexo 项目目录"></a>Hexo 项目目录</h1><h2 id="Init"><a href="#Init" class="headerlink" title="Init"></a>Init</h2><p>实现对目标目录的初始化</p><pre class=" language-shell"><code class="language-shell"># blogname - 为博客项目准备的目录名hexo init blognamecd blognamenup install</code></pre><h2 id="Catalog"><a href="#Catalog" class="headerlink" title="Catalog"></a>Catalog</h2><p><code>_config.yml</code> -</p><p><code>package.json</code> - 是应用程序信息，通常不需要关心</p><p><code>node_moudles</code> - 用来存放 node 相关的模块，通常不需要关心</p><p><code>scaffolds/</code> - 新建文章时的模板文件</p><p><code>source/</code> - 资源文件夹，存放用户资源</p><p><code>theme/</code> - 主题文件夹，<code>_config.yml</code> 将会在此定位使用的主题</p><h1 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h1><p>记录日常配置中常用的命令信息</p><h2 id="首次初始化"><a href="#首次初始化" class="headerlink" title="首次初始化"></a>首次初始化</h2><pre class=" language-shell"><code class="language-shell">git init # 初始化本地库git remote add origin github仓库地址 # 创建别名git push -u origin master # 初次提交到目标库 - 记录本分支提交的默认参数</code></pre><h2 id="修改提交"><a href="#修改提交" class="headerlink" title="修改提交"></a>修改提交</h2><pre class=" language-shell"><code class="language-shell"># 修改提交到 `github`cd blognamegit checkout master # 使用master分支hexo new "new blogname" # 新建一遍博文git add .git commit -am "message"git push origin master</code></pre><h2 id="本地预览"><a href="#本地预览" class="headerlink" title="本地预览"></a>本地预览</h2><p>注意：配置了 <code>travis ci</code> 会自动检测到博客项目的变更，帮助我们重新部署，因此 <code>修改提交</code> 中不需要重新生成静态文件</p><pre class=" language-shell"><code class="language-shell">hexo clean # 清除缓存和已生成的静态文件hexo generate # 生成静态文件hexo server # 使用静态文件，在本地4000端口进行预览hexo c & hexo g & hexo s # Magic - 达到上述三条命令的效果</code></pre><h2 id="删除博文"><a href="#删除博文" class="headerlink" title="删除博文"></a>删除博文</h2><p>也没有查阅到相关命令，直接在本地删除后就可行了</p><p>最好执行一次 <code>hexo c &amp; hexo g &amp; hexo s</code> 本地先看看，然后在提交仓库确认删除操作</p><h1 id="git-push-相关问题"><a href="#git-push-相关问题" class="headerlink" title="git push 相关问题"></a>git push 相关问题</h1><p>OpenSSL SSL_read: Connection was reset, errno 10054</p><pre class=" language-shell"><code class="language-shell">git config --global http.sslVerify "false"</code></pre><p>Failed to connect to github.com port 443:connection timed out</p><pre class=" language-shell"><code class="language-shell">git config --global http.proxy http://127.0.0.1:1080git config --global https.proxy http://127.0.0.1:1080</code></pre><p>上述设置后应该就ok了，如果再次出现问题，取消上述代理设置应该就 ok 了</p><p>什么原理(⊙o⊙)…</p><pre class=" language-shell"><code class="language-shell">git config --global --unset http.proxygit config --global --unset https.proxy</code></pre><h1 id="很小的问题"><a href="#很小的问题" class="headerlink" title="很小的问题"></a>很小的问题</h1><ol><li>在 <code>_config.yml</code> 中配置标题，如果想使用 <code>’</code> 可以使用双引号括起来，在 <code>yaml</code> 语言中 双引号不会对特殊字符转义。</li><li></li></ol>]]></content>
      
      
      <categories>
          
          <category> Github </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
            <tag> github </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>my first blog</title>
      <link href="/Coming-blog/2021/04/29/my-first-blog/"/>
      <url>/Coming-blog/2021/04/29/my-first-blog/</url>
      
        <content type="html"><![CDATA[<p>Hello I’m Coming.</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> nparr <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">return</span> arr</code></pre>]]></content>
      
      
      <categories>
          
          <category> Hybrid </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> numpy </tag>
            
            <tag> Hello World </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
